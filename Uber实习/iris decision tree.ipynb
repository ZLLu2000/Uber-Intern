{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.datasets import load_iris  \n",
    "\n",
    "\n",
    "class DecisionNode(object):\n",
    "    def __init__(self, f_idx, threshold, value=None, L=None, R=None):\n",
    "        self.f_idx = f_idx  \n",
    "        self.threshold = threshold  \n",
    "        self.value = value \n",
    "        self.L = L  \n",
    "        self.R = R  \n",
    "\n",
    "\n",
    "def find_best_threshold(dataset: np.ndarray, f_idx: int, split_choice: str):  \n",
    "    best_gain = -math.inf \n",
    "    best_gini = math.inf\n",
    "    best_threshold = None\n",
    "    dataset_sorted = sorted(list(set(dataset[:, f_idx].reshape(-1)))) \n",
    "    candidate = [] \n",
    "\n",
    "    for i in range(len(dataset_sorted) - 1):\n",
    "        candidate.append(round((dataset_sorted[i] + dataset_sorted[i + 1]) / 2.0, 2))\n",
    "\n",
    "    for threshold in candidate:\n",
    "        L, R = split_dataset(dataset, f_idx, threshold)  \n",
    "        gain = None\n",
    "        if split_choice == \"gain\":\n",
    "            gain = calculate_gain(dataset, L, R)  \n",
    "            if gain > best_gain:  \n",
    "                best_gain = gain\n",
    "                best_threshold = threshold\n",
    "        if split_choice == \"gain_ratio\":\n",
    "            gain = calculate_gain_ratio(dataset, L, R)\n",
    "            if gain > best_gain:  \n",
    "                best_gain = gain\n",
    "                best_threshold = threshold\n",
    "        if split_choice == \"gini\":\n",
    "            gini = calculate_gini_index(dataset, L, R)\n",
    "            if gini < best_gini:  \n",
    "                best_gini = gini\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_gain\n",
    "\n",
    "\n",
    "def calculate_entropy(dataset: np.ndarray): \n",
    "    scale = dataset.shape[0]  \n",
    "    d = {}\n",
    "    for data in dataset:\n",
    "        key = data[-1]\n",
    "        if key in d:\n",
    "            d[key] += 1\n",
    "        else:\n",
    "            d[key] = 1\n",
    "\n",
    "    entropy = 0.0\n",
    "    for key in d.keys():\n",
    "        p = d[key] / scale\n",
    "        entropy -= p * math.log(p, 2)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_gain(dataset, l, r):\n",
    "    e1 = calculate_entropy(dataset)\n",
    "    e2 = len(l) / len(dataset) * calculate_entropy(l) + len(r) / len(dataset) * calculate_entropy(r)\n",
    "    gain = e1 - e2\n",
    "    return gain\n",
    "\n",
    "\n",
    "def calculate_gain_ratio(dataset, l, r):\n",
    "    gain = calculate_gain(dataset, l, r)\n",
    "    p1 = len(l) / len(dataset)\n",
    "    p2 = len(r) / len(dataset)\n",
    "   \n",
    "    if p1 == 0:\n",
    "        s = p2 * math.log(p2, 2)\n",
    "    elif p2 == 0:\n",
    "        s = p1 * math.log(p1, 2)\n",
    "    else:\n",
    "        s = - p1 * math.log(p1, 2) - p2 * math.log(p2, 2)\n",
    "\n",
    "    gain_ratio = gain / s\n",
    "    return gain_ratio\n",
    "\n",
    "\n",
    "def calculate_gini(dataset: np.ndarray):\n",
    "    scale = dataset.shape[0] \n",
    "    d = {}\n",
    "    for data in dataset:\n",
    "        key = data[-1]\n",
    "        if key in d:\n",
    "            d[key] += 1\n",
    "        else:\n",
    "            d[key] = 1\n",
    "\n",
    "    gini = 1.0\n",
    "    for key in d.keys():\n",
    "        p = d[key] / scale\n",
    "        gini -= p * p\n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_gini_index(dataset, l, r):\n",
    "    gini_index = len(l) / len(dataset) * calculate_gini(l) + len(r) / len(dataset) * calculate_gini(r)\n",
    "    return gini_index\n",
    "\n",
    "\n",
    "def split_dataset(X: np.ndarray, f_idx: int, threshold: float):\n",
    "    L = X[:, f_idx] < threshold\n",
    "    R = ~L\n",
    "    return X[L], X[R]\n",
    "\n",
    "\n",
    "def majority_count(dataset):\n",
    "    class_list = [data[-1] for data in dataset]\n",
    "    return collections.Counter(class_list).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "def build_tree(dataset: np.ndarray, f_idx_list: list, split_choice: str):\n",
    "\n",
    "    class_list = [data[-1] for data in dataset]\n",
    "    if class_list.count(class_list[0]) == len(class_list):\n",
    "        return DecisionNode(None, None, value=class_list[0])\n",
    "    elif len(f_idx_list) == 0:\n",
    "        value = collections.Counter(class_list).most_common(1)[0][0]\n",
    "        return DecisionNode(None, None, value=value)\n",
    "\n",
    "    else:\n",
    "        best_gain = -math.inf\n",
    "        best_gini = math.inf\n",
    "        best_threshold = None\n",
    "        best_f_idx = None\n",
    "\n",
    "        for i in f_idx_list:\n",
    "            threshold, gain = find_best_threshold(dataset, i, split_choice)\n",
    "            if split_choice == \"gini\":\n",
    "                if gain < best_gini:\n",
    "                    best_gini = gain\n",
    "                    best_threshold = threshold\n",
    "                    best_f_idx = i\n",
    "            if split_choice == \"gain\" or split_choice == \"gain_ratio\" :\n",
    "                if gain > best_gain:  \n",
    "                    best_gain = gain\n",
    "                    best_threshold = threshold\n",
    "                    best_f_idx = i\n",
    "\n",
    "        son_f_idx_list = f_idx_list.copy()\n",
    "        son_f_idx_list.remove(best_f_idx)\n",
    "\n",
    "        L, R = split_dataset(dataset, best_f_idx, best_threshold)\n",
    "        if len(L) == 0:\n",
    "            L_tree = DecisionNode(None, None, majority_count(dataset))  \n",
    "        else:\n",
    "            L_tree = build_tree(L, son_f_idx_list, split_choice) \n",
    "\n",
    "        if len(R) == 0:\n",
    "            R_tree = DecisionNode(None, None, majority_count(dataset)) \n",
    "        else:\n",
    "            R_tree = build_tree(R, son_f_idx_list, split_choice)  \n",
    "        return DecisionNode(best_f_idx, best_threshold, value=None, L=L_tree, R=R_tree)\n",
    "\n",
    "\n",
    "def predict_one(model: DecisionNode, data):\n",
    "    if model.value is not None:\n",
    "        return model.value\n",
    "    else:\n",
    "        feature_one = data[model.f_idx]\n",
    "        branch = None\n",
    "        if feature_one >= model.threshold:\n",
    "            branch = model.R \n",
    "        else:\n",
    "            branch = model.L  \n",
    "        return predict_one(branch, data)\n",
    "\n",
    "\n",
    "def predict_accuracy(y_predict, y_test):\n",
    "    y_predict = y_predict.tolist()\n",
    "    y_test = y_test.tolist()\n",
    "    count = 0\n",
    "    for i in range(len(y_predict)):\n",
    "        if int(y_predict[i]) == y_test[i]:\n",
    "            count = count + 1\n",
    "    accuracy = count / len(y_predict)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class SimpleDecisionTree(object):\n",
    "    def __init__(self, split_choice, min_samples: int = 1, min_gain: float = 0, max_depth: Union[int, None] = None,\n",
    "                 max_leaves: Union[int, None] = None):\n",
    "        self.split_choice = split_choice\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        dataset_in = np.c_[X, y]\n",
    "        f_idx_list = [i for i in range(X.shape[1])]\n",
    "        self.my_tree = build_tree(dataset_in, f_idx_list, self.split_choice)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        predict_list = []\n",
    "        for data in X:\n",
    "            predict_list.append(predict_one(self.my_tree, data))\n",
    "\n",
    "        return np.array(predict_list)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    predict_accuracy_all = []\n",
    "\n",
    "    for i in range(10):\n",
    "        iris = load_iris() \n",
    "        x = iris.data  \n",
    "        y = iris.target \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "        predict_accuracy_list = []  \n",
    "        split_choice_list = [\"gain\", \"gain_ratio\", \"gini\"]\n",
    "        for split_choice in split_choice_list:\n",
    "            m = SimpleDecisionTree(split_choice)\n",
    "            m.fit(X_train, y_train)\n",
    "            y_predict = m.predict(X_test)\n",
    "            y_predict_accuracy = predict_accuracy(y_predict, y_test.reshape(-1))\n",
    "            predict_accuracy_list.append(y_predict_accuracy)\n",
    "\n",
    "           \n",
    "        clf = DecisionTreeClassifier()  \n",
    "        clf.fit(X_train, y_train) \n",
    "        predicted = clf.predict(X_test)\n",
    "        predict_accuracy_list.append(clf.score(X_test, y_test))\n",
    "        predict_accuracy_all.append(predict_accuracy_list)\n",
    "\n",
    "    p = numpy.array(predict_accuracy_all)\n",
    "    p = np.round(p, decimals=3)\n",
    "    for i in p:\n",
    "        print(i)\n",
    "    print(p.mean(axis=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
